{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHB7zTzaFKmX"
      },
      "source": [
        "# Artificial IntelligenceApplied toSatellite-based RemoteSensing Data for EarthObservation\n",
        "## Chapter 7 - Example 1: Noise Filter\n",
        "\n",
        "The aim of this project is to implement a model able to filter noise from a sine wave."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rpvRPTaKFa3V"
      },
      "source": [
        "Load the [NumPy](https://numpy.org/) library. NumPy is a library for the Python programming language, adding support for large, multi-dimensional arrays and matrices, along with a large collection of high-level mathematical functions to operate on these arrays."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sFXk5844E898"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SG6SzDYxF7XO"
      },
      "source": [
        "Load the [Matplotlib](https://matplotlib.org/) library. Matplotlib is a plotting library for the Python programming language and its numerical mathematics extension NumPy. It provides an object-oriented API for embedding plots into applications using general-purpose GUI toolkits like Tkinter, wxPython, Qt, or GTK+. There is also a procedural \"pylab\" interface based on a state machine (like OpenGL), designed to closely resemble that of MATLAB, though its use is discouraged. SciPy makes use of Matplotlib.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pjTM_pWPF7tF"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AAVZHBirGhJs"
      },
      "source": [
        "Load some functions from [Tensorflow.Keras](https://www.tensorflow.org/api_docs/python/tf/keras) library. Keras is an API designed for human beings, not machines. Keras follows best practices for reducing cognitive load: it offers consistent & simple APIs, it minimizes the number of user actions required for common use cases, and it provides clear & actionable error messages. It also has extensive documentation and developer guides. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dMwYg5ZUFKW6"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.utils import plot_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KrNmVasxIAsw"
      },
      "source": [
        "## Create the dataset\n",
        "For this simple project the dataset is created on-line. A common practice in Deep Learning is the use of generators. Basically a generator is composed of an infinite while loop and of the yield keyword. The generator is used to avoid memory problems, infact the datast is not loaded all in once, but batch by batch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XwVIuXj_IEXi"
      },
      "outputs": [],
      "source": [
        "def dataset_generator(batch_size, time_size): \n",
        "  x_train = np.zeros((batch_size, time_size))\n",
        "  y_train = np.zeros((batch_size, time_size))\n",
        "  t = np.linspace(-3*np.pi, 3*np.pi, time_size)\n",
        "\n",
        "  while True:\n",
        "      \n",
        "    for i in range(batch_size):\n",
        "      # Create random sine waves with\n",
        "      m = np.random.randint(1, 4)\n",
        "      d = np.random.randint(-90, 90)\n",
        "\n",
        "      x_train[i,...] = np.sin(m*t + d)/2.0\n",
        "      y_train[i,...] = np.sin(m*t + d)/2.0\n",
        "      # Add noise to x_train\n",
        "      for dt in range(time_size):\n",
        "        error = np.random.normal(0, 1, size = 1)\n",
        "        x_train[i, dt] = x_train[i, dt] + 0.3*error/2.0\n",
        "\n",
        "    yield x_train, y_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ylxaR3QEJUzs"
      },
      "source": [
        "To call the generator you should use the following commands"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LinVzEq1JR5R"
      },
      "outputs": [],
      "source": [
        "# Create an instance of the dataset_generator\n",
        "generator = dataset_generator(32, 300)\n",
        "\n",
        "# Get the iterator from the generator \n",
        "iterator = iter(generator)\n",
        "\n",
        "# Get a batch of data\n",
        "x_train, y_train = next(iterator)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uNCOtSHdJ2h5"
      },
      "source": [
        "Let have a look of x_train and y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "bx4vCuZXJ1xc",
        "outputId": "458048d4-921c-44f8-a626-9ec96ec3866c"
      },
      "outputs": [],
      "source": [
        "print('x_train shape: ', x_train.shape, 'y_train shape: ', y_train.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5JuyfGyKJcw"
      },
      "source": [
        "As you can see both the x_train and y_train have the same shape (batch_size, lenght). Let plot an example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "StDIJjwWJnar",
        "outputId": "d185030b-391d-4721-faa8-762d91ac3043"
      },
      "outputs": [],
      "source": [
        "for _ in range(4):\n",
        "\n",
        "  sample =  np.random.randint(0, x_train.shape[0])\n",
        "  t = np.linspace(-3*np.pi, 3*np.pi, x_train.shape[1])\n",
        "\n",
        "  fig, ax = plt.subplots(nrows = 1, ncols = 1, figsize = (15,9))\n",
        "\n",
        "  ax.plot(t, x_train[sample, ...], label = 'Sample from x_train, sine wave with noise')\n",
        "  ax.plot(t, y_train[sample, ...], label = 'Sample from y_train, sine wave without noise')\n",
        "\n",
        "  ax.set_xlabel('Time', fontsize = 20)\n",
        "  ax.set_ylabel('Amplitutde', fontsize = 20)\n",
        "  ax.set_title('Sine wave without noise VS Sine wave with noise', fontsize = 28)\n",
        "\n",
        "  ax.legend(fontsize = 20)\n",
        "  ax.grid()\n",
        "\n",
        "\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7S_bOSGkNDMi"
      },
      "source": [
        "# Build a model\n",
        "\n",
        "The model is composed of different Dense layer, with a size defined by the variable time_size and the Tanh as activation function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y4O0l7qJK-tt"
      },
      "outputs": [],
      "source": [
        "time_size =  x_train.shape[1]\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(time_size, input_dim=time_size, activation='tanh'))\n",
        "model.add(Dense(time_size/2, activation='tanh'))\n",
        "model.add(Dense(time_size/4, activation='tanh'))\n",
        "model.add(Dense(time_size, activation='tanh'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1wjoqN_NUhU"
      },
      "source": [
        "Compile the model using the MSE as loss function and Adam as optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-0eMRRiINT11"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='mae', optimizer='adam')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KcH89YmcN4Tz"
      },
      "source": [
        "Show the model structure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "Dy5bLIXANSxE",
        "outputId": "3eacdb7e-5bdc-48e0-dfac-d69257c279c2"
      },
      "outputs": [],
      "source": [
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0-plVRBOMDu"
      },
      "source": [
        "# Model training\n",
        "The model will be trained with the function fit_generator, for 20 epcohs. This function uses generators, both for training and validations set. Since the generator are producing an infiniry of samples, using steps_per_epoch and validation_step, the user can define an arbitrary size for the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 712
        },
        "id": "13QA2XTnN5_H",
        "outputId": "e4a3ae95-4fd4-4a96-f10a-13e88ca83268"
      },
      "outputs": [],
      "source": [
        "history = model.fit_generator(\n",
        "  dataset_generator(32, time_size),\n",
        "  steps_per_epoch=10000//32,\n",
        "  validation_data=dataset_generator(16, time_size),\n",
        "  validation_steps=10000//16,\n",
        "  epochs=20\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pIXADwF8P70C"
      },
      "source": [
        "Plot the training score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "Zj6CUwiLPpVA",
        "outputId": "5b9c3999-70bb-4192-be2d-637b241d6a4d"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(nrows=1, ncols=1, figsize = (15, 6))\n",
        "ax.plot(history.history['loss'], label = 'Training Loss')\n",
        "ax.plot(history.history['val_loss'], label = 'Validation Loss')\n",
        "\n",
        "ax.set_title('Training VS Validation Loss')\n",
        "ax.set_xlabel('Epochs')\n",
        "ax.set_xlabel('MAE')\n",
        "\n",
        "ax.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lcMM4hnFTrpJ"
      },
      "source": [
        "# Test the trained model\n",
        "\n",
        "Load new samples through the generator and predict the output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "197ttctcTuuC"
      },
      "outputs": [],
      "source": [
        "x_train, y_train = next(iter(dataset_generator(10, time_size)))\n",
        "pred = model.predict(x_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJGJgssfT5-Y"
      },
      "source": [
        "Plot the results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "zhEgK79BIgJA",
        "outputId": "f33323d9-d9e4-4dd4-ad74-05285d97d050"
      },
      "outputs": [],
      "source": [
        "for i in range(4):\n",
        "  fig, axes = plt.subplots(nrows=2, ncols=1, figsize = (15, 12))\n",
        "\n",
        "  t = np.linspace(-3*np.pi, 3*np.pi, time_size)\n",
        "  axes[0].plot(t, x_train[0,...], label = 'Additive noise')\n",
        "  axes[0].plot(t, y_train[0,...], label = 'Ground Truth')\n",
        "  axes[0].plot(t, pred[0,...], '-.',label = 'Model Prediction')\n",
        "\n",
        "  axes[0].set_title('Sine wave without noise VS Sine wave with noise VS Sine wave predicted by the model')\n",
        "\n",
        "  axes[0].legend()\n",
        "  axes[0].grid()\n",
        "\n",
        "  axes[1].plot(t[50:100], y_train[0,50:100], label = 'Ground Truth')\n",
        "  axes[1].plot(t[50:100], pred[0,50:100], label = 'Model Prediction')\n",
        "  axes[1].set_title('Zoom')\n",
        "\n",
        "  axes[1].legend()\n",
        "  axes[1].grid()\n",
        "\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UQpF6TkDIlU2"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "NoiseFilter.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
